{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FRIENDS_Chat_Keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "2yuLVmxLUtFz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Importing Files"
      ]
    },
    {
      "metadata": {
        "id": "Bqg6MWfhJS1_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N8boPJkXJUjT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install --upgrade gensim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-szOut1oJaw4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "import gensim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7fcAvLeeLoLx",
        "colab_type": "code",
        "outputId": "1212bf32-1665-4d25-83e9-eec87e58529a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e5_snl4rU0lf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Loading Friends Transcripts data"
      ]
    },
    {
      "metadata": {
        "id": "KzwrT3xrJvFY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "friends_data=pd.read_csv('/content/drive/My Drive/friends-final.txt',sep=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ErSmuQPqKrLb",
        "colab_type": "code",
        "outputId": "e56ed53a-ee3e-4f25-d459-767da9415c62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "friends_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>scene_id</th>\n",
              "      <th>person</th>\n",
              "      <th>gender</th>\n",
              "      <th>original_line</th>\n",
              "      <th>line</th>\n",
              "      <th>metadata</th>\n",
              "      <th>filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>MONICA</td>\n",
              "      <td>F</td>\n",
              "      <td>Monica: There's nothing to tell! He's just som...</td>\n",
              "      <td>Theres nothing to tell Hes just some guy I wor...</td>\n",
              "      <td>There_EX 's_VBZ nothing_PN1 to_TO tell_VVI !_!...</td>\n",
              "      <td>0101.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>101</td>\n",
              "      <td>1</td>\n",
              "      <td>JOEY</td>\n",
              "      <td>M</td>\n",
              "      <td>Joey: C'mon, you're going out with the guy! Th...</td>\n",
              "      <td>Cmon youre going out with the guy Theres gotta...</td>\n",
              "      <td>C'm_VV0 on_RP you_PPY 're_VBR going_VVG out_RP...</td>\n",
              "      <td>0101.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>201</td>\n",
              "      <td>1</td>\n",
              "      <td>CHANDLER</td>\n",
              "      <td>M</td>\n",
              "      <td>Chandler: All right Joey, be nice.  So does he...</td>\n",
              "      <td>Alright Joey be nice So does he have a hump A ...</td>\n",
              "      <td>All_RR21 right_RR22 Joey_NP1 be_VBI nice_JJ ._...</td>\n",
              "      <td>0101.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>301</td>\n",
              "      <td>1</td>\n",
              "      <td>PHOEBE</td>\n",
              "      <td>F</td>\n",
              "      <td>Phoebe: Wait, does he eat chalk?</td>\n",
              "      <td>Wait does he eat chalk</td>\n",
              "      <td>Wait_VV0 does_VDZ he_PPHS1 eat_VVI chalk_NN1 ?_?</td>\n",
              "      <td>0101.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>401</td>\n",
              "      <td>1</td>\n",
              "      <td>PHOEBE</td>\n",
              "      <td>F</td>\n",
              "      <td>Phoebe: Just, 'cause, I don't want her to go t...</td>\n",
              "      <td>Just cause I dont want her to go through what ...</td>\n",
              "      <td>Just_RR 'cause_CS I_PPIS1 do_VD0 n't_XX want_V...</td>\n",
              "      <td>0101.txt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id scene_id    person gender  \\\n",
              "0    1        1    MONICA      F   \n",
              "1  101        1      JOEY      M   \n",
              "2  201        1  CHANDLER      M   \n",
              "3  301        1    PHOEBE      F   \n",
              "4  401        1    PHOEBE      F   \n",
              "\n",
              "                                       original_line  \\\n",
              "0  Monica: There's nothing to tell! He's just som...   \n",
              "1  Joey: C'mon, you're going out with the guy! Th...   \n",
              "2  Chandler: All right Joey, be nice.  So does he...   \n",
              "3                   Phoebe: Wait, does he eat chalk?   \n",
              "4  Phoebe: Just, 'cause, I don't want her to go t...   \n",
              "\n",
              "                                                line  \\\n",
              "0  Theres nothing to tell Hes just some guy I wor...   \n",
              "1  Cmon youre going out with the guy Theres gotta...   \n",
              "2  Alright Joey be nice So does he have a hump A ...   \n",
              "3                             Wait does he eat chalk   \n",
              "4  Just cause I dont want her to go through what ...   \n",
              "\n",
              "                                            metadata  filename  \n",
              "0  There_EX 's_VBZ nothing_PN1 to_TO tell_VVI !_!...  0101.txt  \n",
              "1  C'm_VV0 on_RP you_PPY 're_VBR going_VVG out_RP...  0101.txt  \n",
              "2  All_RR21 right_RR22 Joey_NP1 be_VBI nice_JJ ._...  0101.txt  \n",
              "3   Wait_VV0 does_VDZ he_PPHS1 eat_VVI chalk_NN1 ?_?  0101.txt  \n",
              "4  Just_RR 'cause_CS I_PPIS1 do_VD0 n't_XX want_V...  0101.txt  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "0khUxsns-7TK",
        "colab_type": "code",
        "outputId": "0479b33c-6a41-4b8e-f44e-c89f1c2e0301",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "friends_data.iloc[len(friends_data)-1]['original_line']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Chandler: Sure. Where?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "H4Fux08cU8lr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Removing Punctuations"
      ]
    },
    {
      "metadata": {
        "id": "r2ePc-ZPr2Ax",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "friends_data[\"line\"] = friends_data['line'].str.replace('[^\\w\\s]','')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bTGm0YHZXeNV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "friends_data['line'] = friends_data['line'].str.replace(',','')\n",
        "friends_data['line'] = friends_data['line'].str.replace('.',' ')\n",
        "friends_data['line'] = friends_data['line'].str.replace('!','')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qAMXwo88VfBj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Dialogue count of each of the characters"
      ]
    },
    {
      "metadata": {
        "id": "x8Qc3xlGNLHe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1071
        },
        "outputId": "ee8873d8-1b17-442a-b5a9-858d9dcaec7a"
      },
      "cell_type": "code",
      "source": [
        "friends_data.person.value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RACHEL                             9207\n",
              "ROSS                               9027\n",
              "CHANDLER                           8362\n",
              "MONICA                             8324\n",
              "JOEY                               8125\n",
              "PHOEBE                             7453\n",
              "MIKE                                358\n",
              "ALL                                 343\n",
              "RICHARD                             281\n",
              "JANICE                              217\n",
              "MR. GELLER                          204\n",
              "CAROL                               193\n",
              "CHARLIE                             190\n",
              "EMILY                               167\n",
              "MRS. GELLER                         164\n",
              "TAG                                 146\n",
              "FRANK                               146\n",
              "DIRECTOR                            135\n",
              "PAUL                                133\n",
              "GUNTHER                             130\n",
              "AMY                                 122\n",
              "DAVID                               120\n",
              "MONA                                111\n",
              "WOMAN                               105\n",
              "SUSAN                               104\n",
              "PETE                                103\n",
              "JOSHUA                               98\n",
              "GARY                                 96\n",
              "ELIZABETH                            94\n",
              "JANINE                               92\n",
              "                                   ... \n",
              "WOMAN'S VOICE                         1\n",
              "MONICA, ROSS, AND JOEY                1\n",
              "SHERMAN WHITFIELD                     1\n",
              "THE WHOLE PARTY                       1\n",
              "PHOEBE'S FRIENDS                      1\n",
              "MATTHEW PERRY                         1\n",
              "CHANDLER, PHOEBE, AND RACHEL          1\n",
              "MEL                                   1\n",
              "DONNY OSMOND                          1\n",
              "REFEREE                               1\n",
              "JOEY, CHANDLER, AND ROSS              1\n",
              "ZOE                                   1\n",
              "PHOEBE AND LESLIE                     1\n",
              "HEALTH INSPECTOR                      1\n",
              "ELIZABETH HORNSWOGGLE                 1\n",
              "ROSS AND BONNIE                       1\n",
              "OLD WOMAN                             1\n",
              "MONICA, RACHEL, AND JOEY              1\n",
              "MS. GELLER                            1\n",
              "CHASE LASSITER                        1\n",
              "LISA KUDROW                           1\n",
              "RACHEL'S BOSS                         1\n",
              "EVERYONE BUT MONICA                   1\n",
              "MONICA, CHANDLER, ROSS                1\n",
              "ANOTHER TOUR GUIDE                    1\n",
              "JOEY'S VOICE, BUT SHE SEES ROSS       1\n",
              "RACHEL AND CHANDLER                   1\n",
              "A WAITER                              1\n",
              "PARTY GUESTS                          1\n",
              "ANOTHER EXTRA                         1\n",
              "Name: person, Length: 803, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "kjcttsj_Yjej",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "friends_data[friends_data]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VF2-iUVFVszw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# We tried 3 approaches to create context-response pairs"
      ]
    },
    {
      "metadata": {
        "id": "DpQnD-ZCNPfB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x=[]\n",
        "y=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UV4s677UVzRf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Approach 1: Concatenation of All dialogues previous to Ross as Context and Ross's Dialogue as Reply"
      ]
    },
    {
      "metadata": {
        "id": "eK3-G-ShNVdD",
        "colab_type": "code",
        "outputId": "f0823314-2f8c-4861-dd4e-2ee233e74a43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "s=\"\"\n",
        "for index,row in friends_data.iterrows():\n",
        "    if row['person']==\"ROSS\":\n",
        "        y.append(row['line'])\n",
        "        x.append(s)\n",
        "        s=\"\"\n",
        "    else:\n",
        "        s+=row['line']\n",
        "        \n",
        "print(x[:1])\n",
        "print(y[:1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Theres nothing to tell Hes just some guy I work withCmon youre going out with the guy Theres gotta be something wrong with himAlright Joey be nice So does he have a hump A hump and a hairpieceWait does he eat chalkJust cause I dont want her to go through what I went through with Carl ohOkay everybody relax This is not even a date Its just two people going out to dinner and not having sexSounds like a date to meAlright so Im back in high school Im standing in the middle of the cafeteria and I realize I am totally nakedOh yeah Had that dreamThen I look down and I realize theres a phone thereInstead ofThats rightNever had that dreamNoAll of a sudden the phone starts to ring Now I dont know what to do everybody starts looking at meAnd they werent looking at you beforeFinally I figure Id better answer it and it turns out its my mother which is very very weird because she never calls me']\n",
            "['Hi']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MRWE69C3WAiM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Approach 2: Sequential (Dialogue 1-2 as one pair, 2-3 as another pair and so on..)"
      ]
    },
    {
      "metadata": {
        "id": "BrkIlfB6bcHA",
        "colab_type": "code",
        "outputId": "3bfcf022-db16-4e6b-c0c8-815bb8bd04e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "for i in range(len(friends_data)-1):\n",
        "  x.append(friends_data.iloc[i]['line'])\n",
        "  y.append(friends_data.iloc[i+1]['line'])\n",
        "print(x[:1])\n",
        "print(y[:1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Theres nothing to tell Hes just some guy I work with']\n",
            "['Cmon youre going out with the guy Theres gotta be something wrong with him']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ia3uJ3-CWRQp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Approach 3: All dialogues previous to Ross individually taken as Context as opposed to Ross's reply. (Best Model)"
      ]
    },
    {
      "metadata": {
        "id": "abJO9DybaWRD",
        "colab_type": "code",
        "outputId": "216b11f0-42b7-489c-83a1-b7201b453ab9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "temp=[]\n",
        "for index,row in friends_data.iterrows():\n",
        "    if row['person']==\"ROSS\":\n",
        "        for item in temp:\n",
        "          y.append(row['line'])\n",
        "          x.append(item)\n",
        "        temp=[]\n",
        "    else:\n",
        "        temp.append(row['line'])\n",
        "        \n",
        "print(x[:2])\n",
        "print(y[:2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Theres nothing to tell Hes just some guy I work with', 'Cmon youre going out with the guy Theres gotta be something wrong with him']\n",
            "['Hi', 'Hi']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SD-iCdUJWi5L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Length of X-Y (Context Response Pairs) Lists"
      ]
    },
    {
      "metadata": {
        "id": "Rnts53I-NX8Z",
        "colab_type": "code",
        "outputId": "617d768e-ea98-4159-d1eb-d904c112f8ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(x))\n",
        "print(len(y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "51812\n",
            "51812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "galQCX83NilJ",
        "colab_type": "code",
        "outputId": "9920e669-17fa-486c-e674-362788832c4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "x6KgVpN2WoFB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Tokenisation"
      ]
    },
    {
      "metadata": {
        "id": "TSYeEcvSNcky",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tok_x=[]\n",
        "tok_y=[]\n",
        "for i in range(len(x)):\n",
        "    tok_x.append(nltk.word_tokenize(x[i].lower()))\n",
        "    tok_y.append(nltk.word_tokenize(y[i].lower()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8_ubdCHsNfzq",
        "colab_type": "code",
        "outputId": "eb2ba976-46e0-4785-c6db-fadc481fca7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "cell_type": "code",
      "source": [
        "tok_x[:2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['theres',\n",
              "  'nothing',\n",
              "  'to',\n",
              "  'tell',\n",
              "  'hes',\n",
              "  'just',\n",
              "  'some',\n",
              "  'guy',\n",
              "  'i',\n",
              "  'work',\n",
              "  'with'],\n",
              " ['cmon',\n",
              "  'youre',\n",
              "  'going',\n",
              "  'out',\n",
              "  'with',\n",
              "  'the',\n",
              "  'guy',\n",
              "  'theres',\n",
              "  'got',\n",
              "  'ta',\n",
              "  'be',\n",
              "  'something',\n",
              "  'wrong',\n",
              "  'with',\n",
              "  'him']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "metadata": {
        "id": "8xwv1q9fNuXc",
        "colab_type": "code",
        "outputId": "19c26065-8c95-4fbc-8071-97510b109277",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1173
        }
      },
      "cell_type": "code",
      "source": [
        "tok_y[:20]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['hi'],\n",
              " ['hi'],\n",
              " ['hi'],\n",
              " ['hi'],\n",
              " ['hi'],\n",
              " ['hi'],\n",
              " ['hi'],\n",
              " ['hi'],\n",
              " ['hi'],\n",
              " ['hi'],\n",
              " ['hi'],\n",
              " ['hi'],\n",
              " ['hi'],\n",
              " ['hi'],\n",
              " ['hi'],\n",
              " ['hi'],\n",
              " ['hi'],\n",
              " ['i',\n",
              "  'just',\n",
              "  'feel',\n",
              "  'like',\n",
              "  'someone',\n",
              "  'reached',\n",
              "  'down',\n",
              "  'my',\n",
              "  'throat',\n",
              "  'grabbed',\n",
              "  'my',\n",
              "  'small',\n",
              "  'intestine',\n",
              "  'pulled',\n",
              "  'it',\n",
              "  'out',\n",
              "  'of',\n",
              "  'my',\n",
              "  'mouth',\n",
              "  'and',\n",
              "  'tied',\n",
              "  'it',\n",
              "  'around',\n",
              "  'my',\n",
              "  'neck'],\n",
              " ['i',\n",
              "  'just',\n",
              "  'feel',\n",
              "  'like',\n",
              "  'someone',\n",
              "  'reached',\n",
              "  'down',\n",
              "  'my',\n",
              "  'throat',\n",
              "  'grabbed',\n",
              "  'my',\n",
              "  'small',\n",
              "  'intestine',\n",
              "  'pulled',\n",
              "  'it',\n",
              "  'out',\n",
              "  'of',\n",
              "  'my',\n",
              "  'mouth',\n",
              "  'and',\n",
              "  'tied',\n",
              "  'it',\n",
              "  'around',\n",
              "  'my',\n",
              "  'neck'],\n",
              " ['thanks']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "metadata": {
        "id": "6I1RXYifWs5D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Word Embeddings using Gensim"
      ]
    },
    {
      "metadata": {
        "id": "NE60AYTQNwjZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model=Word2Vec(tok_x+tok_y,min_count=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VpPcXOoMN4An",
        "colab_type": "code",
        "outputId": "f96a1b44-8ffa-4958-a75a-8fd6f939b06a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "print(modelW2[\"there\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.084215   0.69597    0.28383   -0.22497   -0.55923    0.21196\n",
            " -0.15175    0.31601    0.24803   -0.36385    0.2252     0.34109\n",
            "  0.61438    0.08318    0.74894   -0.38785   -0.27211    0.2656\n",
            " -0.66332    0.45571    0.34949    0.38635    0.25707   -0.60101\n",
            " -0.047292  -0.41198    0.38246   -0.52151    0.037757  -0.42492\n",
            " -0.36352   -0.037377   0.31263    0.19709    0.008142   0.53871\n",
            " -0.074505   0.31395    0.35129   -0.39005   -0.5474    -0.11395\n",
            "  0.076668  -0.61069    0.15894   -0.33043    0.75967   -0.52289\n",
            " -0.38957   -0.71164    0.28724   -0.35683    0.050529   1.3392\n",
            " -0.16064   -2.9236     0.17524   -0.42109    1.5235     0.85181\n",
            " -0.47563    1.1225    -0.48463    0.36458    0.97809   -0.2227\n",
            "  0.88791    0.068738   0.22557    0.026459  -0.032799  -0.40426\n",
            "  0.14579   -0.4535     0.47756    0.15933    0.24236    0.0091798\n",
            " -1.3502    -0.078424   0.57803   -0.50061   -0.19374    0.29587\n",
            " -1.2316    -0.099825   0.31661   -0.46539   -0.54243   -0.13506\n",
            " -0.12897   -0.29543   -0.28094    0.092313  -0.78078   -0.097087\n",
            " -0.57313   -0.54       0.58031    0.46698  ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y2urnHObN6u_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vec_x=[]\n",
        "vec_y=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zAjnO9CKWz81",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Sentence Embeddings"
      ]
    },
    {
      "metadata": {
        "id": "TQuWFbBFN_E0",
        "colab_type": "code",
        "outputId": "21e5ca50-cdb8-450f-aac5-04c04653a421",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "for sent in tok_x:\n",
        "    sentvec=[modelW2[w] for w in sent if w in modelW2.wv.vocab]\n",
        "    vec_x.append(sentvec)\n",
        "for sent in tok_y:\n",
        "    sentvec=[modelW2[w] for w in sent if w in modelW2.wv.vocab]\n",
        "    vec_y.append(sentvec)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "fW5PpD3HCGV2",
        "colab_type": "code",
        "outputId": "63bb2c19-744b-430c-d835-4687bab340ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "vec_x[0][0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "metadata": {
        "id": "KFMD9QzyW3Qk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Padding/Truncating To make sentences even length (15)"
      ]
    },
    {
      "metadata": {
        "id": "gpMBoRVUVVog",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentend=np.ones(100,dtype=np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RgcN93b-UhSD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for tok_sent in vec_x:\n",
        "  tok_sent[14:]=[]\n",
        "  tok_sent.append(sentend)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c9a5SBvqWSwr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for tok_sent in vec_x:\n",
        "  if(len(tok_sent)<15):\n",
        "    for i in range(15-len(tok_sent)):\n",
        "      tok_sent.append(sentend)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ps9OC9WpV7tt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for tok_sent in vec_y:\n",
        "  tok_sent[14:]=[]\n",
        "  tok_sent.append(sentend)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wc9JSsGEWxzp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for tok_sent in vec_y:\n",
        "  if(len(tok_sent)<15):\n",
        "    for i in range(15-len(tok_sent)):\n",
        "      tok_sent.append(sentend)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wMIEvTkK5fdn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# size = 0\n",
        "# for i in vec_x:\n",
        "#   size = max(size, len(i))\n",
        "# print(size)\n",
        "\n",
        "\n",
        "# for i in vec_x:\n",
        "#   size = max(size, len(i))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_VAAKJwLOFrd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vec_X=np.array(vec_x,dtype=np.float64)\n",
        "vec_Y=np.array(vec_y,dtype=np.float64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gUm14iUPdsN7",
        "colab_type": "code",
        "outputId": "c5dac0e4-9328-4a32-f8b2-546aa6bbba19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "vec_X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(51812, 15, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "metadata": {
        "id": "il2zcWnidON2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U scikit-learn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4h71UIDKdEgI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3PoVAOzkXCCC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Splitting into Training and Testing (80:20)"
      ]
    },
    {
      "metadata": {
        "id": "hpnQUexvavHu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(vec_X,vec_Y,test_size=0.2,random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "79chDS3Yd63m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !pip install keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EWB6b6Iod2Mq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tjDKkapcduij",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model1=Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wjcPLHA1eHii",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# x_train=tf.keras.utils.normalize(x_train,axis=1)\n",
        "# x_test=tf.keras.utils.normalize(x_test,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qWWg2hcFhs5R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers.recurrent import LSTM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SGsCO3A2jLpK",
        "colab_type": "code",
        "outputId": "6148958a-2f6b-4a7a-945d-a2bf65b88693",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41449, 15, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "metadata": {
        "id": "ts-3pTNZkScv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Bidirectional"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SP-vHfxrXKs8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# A single Layer Attention based Bidirectional LSTM with Hidden Size 256  (Best Model)"
      ]
    },
    {
      "metadata": {
        "id": "rDnt83_-emn-",
        "colab_type": "code",
        "outputId": "c851451e-ea17-49df-9eb9-9ba30935b138",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "model1.add(Bidirectional(LSTM(256,input_shape=(15,100),return_sequences=True,init='glorot_normal',inner_init='glorot_normal',activation='tanh')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(256, input_shape=(15, 100), return_sequences=True, activation=\"tanh\", kernel_initializer=\"glorot_normal\", recurrent_initializer=\"glorot_normal\")`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "HKBg6fVSXVPF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Attention layer"
      ]
    },
    {
      "metadata": {
        "id": "J2Lg6KYOBn-y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model1.add(AttentionDecoder(256, 100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yLFf4hdlhjQi",
        "colab_type": "code",
        "outputId": "17b5283f-70ca-4924-da04-74913b6456a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "# model1.add(Bidirectional(LSTM(output_dim=50,input_shape=(None,100),return_sequences=True,init='glorot_normal',inner_init='glorot_normal',activation='tanh')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(input_shape=(None, 100..., return_sequences=True, activation=\"tanh\", units=50, kernel_initializer=\"glorot_normal\", recurrent_initializer=\"glorot_normal\")`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Kb6lZb1Lhj56",
        "colab_type": "code",
        "outputId": "a3f22165-e293-41f2-8139-89f70d35b39c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "# model1.add(Bidirectional(LSTM(output_dim=50,input_shape=(None,100),return_sequences=True,init='glorot_normal',inner_init='glorot_normal',activation='tanh')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(input_shape=(None, 100..., return_sequences=True, activation=\"tanh\", units=50, kernel_initializer=\"glorot_normal\", recurrent_initializer=\"glorot_normal\")`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "9ckDpV2ahkdi",
        "colab_type": "code",
        "outputId": "ab50b77b-3db1-411c-ef5f-57737969d381",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "# model1.add(Bidirectional(LSTM(output_dim=50,input_shape=(None,100),return_sequences=True,init='glorot_normal',inner_init='glorot_normal',activation='tanh')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(input_shape=(None, 100..., return_sequences=True, activation=\"tanh\", units=50, kernel_initializer=\"glorot_normal\", recurrent_initializer=\"glorot_normal\")`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Klm7xXeGXYJe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Cross Entropy Loss (Best model)"
      ]
    },
    {
      "metadata": {
        "id": "zsiZGtT1A-zD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model1.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Lf4uXcsBoPE",
        "colab_type": "code",
        "outputId": "ec53b396-31bd-410b-dc54-c81fe4e01959",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        }
      },
      "cell_type": "code",
      "source": [
        "model1.fit(x_train,y_train,nb_epoch=10,validation_data=(x_test,y_test))\n",
        "model1.save('LSTM10.h5')\n",
        "from google.colab import files\n",
        "files.download('LSTM10.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 41449 samples, validate on 10363 samples\n",
            "Epoch 1/10\n",
            "41449/41449 [==============================] - 695s 17ms/step - loss: 212.9045 - acc: 0.2312 - val_loss: 208.5366 - val_acc: 0.2224\n",
            "Epoch 2/10\n",
            "41449/41449 [==============================] - 620s 15ms/step - loss: 212.0599 - acc: 0.2398 - val_loss: 208.5739 - val_acc: 0.2434\n",
            "Epoch 3/10\n",
            "41449/41449 [==============================] - 599s 14ms/step - loss: 212.0224 - acc: 0.2407 - val_loss: 208.7000 - val_acc: 0.2522\n",
            "Epoch 4/10\n",
            "41449/41449 [==============================] - 586s 14ms/step - loss: 211.9527 - acc: 0.2430 - val_loss: 208.4408 - val_acc: 0.2475\n",
            "Epoch 5/10\n",
            "41449/41449 [==============================] - 617s 15ms/step - loss: 211.9393 - acc: 0.2422 - val_loss: 208.4160 - val_acc: 0.2468\n",
            "Epoch 6/10\n",
            "41449/41449 [==============================] - 661s 16ms/step - loss: 211.8909 - acc: 0.2448 - val_loss: 208.4068 - val_acc: 0.2612\n",
            "Epoch 7/10\n",
            "41449/41449 [==============================] - 587s 14ms/step - loss: 211.7998 - acc: 0.2431 - val_loss: 208.5404 - val_acc: 0.2426\n",
            "Epoch 8/10\n",
            "41449/41449 [==============================] - 642s 15ms/step - loss: 211.7202 - acc: 0.2430 - val_loss: 208.6632 - val_acc: 0.2401\n",
            "Epoch 9/10\n",
            "41449/41449 [==============================] - 618s 15ms/step - loss: 211.5693 - acc: 0.2397 - val_loss: 208.5733 - val_acc: 0.2349\n",
            "Epoch 10/10\n",
            "41449/41449 [==============================] - 672s 16ms/step - loss: 211.4322 - acc: 0.2407 - val_loss: 208.6186 - val_acc: 0.2440\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-d92e3bfac4e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LSTM10.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LSTM10.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   })\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Oagmp5ApXfQv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "6AZd9vQgeyJg",
        "colab_type": "code",
        "outputId": "e4cf0c8f-c65e-43bb-c73a-3d4456a81436",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 929
        }
      },
      "cell_type": "code",
      "source": [
        "model1.fit(x_train,y_train,nb_epoch=10,validation_data=(x_test,y_test))\n",
        "model1.save('LSTM20.h5')\n",
        "from google.colab import files\n",
        "files.download('LSTM20.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 41449 samples, validate on 10363 samples\n",
            "Epoch 1/10\n",
            "41449/41449 [==============================] - 524s 13ms/step - loss: 211.1163 - acc: 0.2395 - val_loss: 209.5597 - val_acc: 0.2506\n",
            "Epoch 2/10\n",
            "41449/41449 [==============================] - 513s 12ms/step - loss: 210.7780 - acc: 0.2357 - val_loss: 209.2274 - val_acc: 0.2476\n",
            "Epoch 3/10\n",
            "41449/41449 [==============================] - 525s 13ms/step - loss: 210.2182 - acc: 0.2358 - val_loss: 209.2158 - val_acc: 0.2337\n",
            "Epoch 4/10\n",
            "41449/41449 [==============================] - 512s 12ms/step - loss: 209.5624 - acc: 0.2409 - val_loss: 210.0831 - val_acc: 0.2563\n",
            "Epoch 5/10\n",
            "41449/41449 [==============================] - 510s 12ms/step - loss: 208.8746 - acc: 0.2349 - val_loss: 210.9163 - val_acc: 0.2364\n",
            "Epoch 6/10\n",
            "41449/41449 [==============================] - 508s 12ms/step - loss: 208.0088 - acc: 0.2353 - val_loss: 211.3485 - val_acc: 0.2378\n",
            "Epoch 7/10\n",
            "41449/41449 [==============================] - 500s 12ms/step - loss: 207.1530 - acc: 0.2384 - val_loss: 212.2729 - val_acc: 0.2500\n",
            "Epoch 8/10\n",
            "41449/41449 [==============================] - 509s 12ms/step - loss: 206.2273 - acc: 0.2406 - val_loss: 213.1715 - val_acc: 0.2449\n",
            "Epoch 9/10\n",
            "41449/41449 [==============================] - 514s 12ms/step - loss: 205.1969 - acc: 0.2391 - val_loss: 215.8153 - val_acc: 0.2436\n",
            "Epoch 10/10\n",
            "41449/41449 [==============================] - 520s 13ms/step - loss: 204.2367 - acc: 0.2388 - val_loss: 214.4037 - val_acc: 0.2430\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-060aea08fbf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LSTM20.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LSTM20.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   })\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "xmUE15wkezP8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model1.fit(x_train,y_train,nb_epoch=10,validation_data=(x_test,y_test))\n",
        "model1.save('LSTM30.h5')\n",
        "from google.colab import files\n",
        "files.download('LSTM30.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qn9SNdTpez2k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model1.fit(x_train,y_train,nb_epoch=10,validation_data=(x_test,y_test))\n",
        "model1.save('LSTM40.h5')\n",
        "from google.colab import files\n",
        "files.download('LSTM40.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YAAchLFye0YN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model1.fit(x_train,y_train,nb_epoch=10,validation_data=(x_test,y_test))\n",
        "model1.save('LSTM50.h5')\n",
        "from google.colab import files\n",
        "files.download('LSTM50.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W2n8G_uOF_1V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions=model1.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wzFLTjB6H57C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "[model.most_similar([predictions[1999][i]])[0] for i in range(15)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0bP_CFH2Icoy",
        "colab_type": "code",
        "outputId": "6300b7a7-db11-4243-a221-a71fca53edf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "    x=\"coffee?\";\n",
        "    sentend=np.ones((100,),dtype=np.float32) \n",
        "\n",
        "    sent=nltk.word_tokenize(x.lower())\n",
        "    sentvec = [model[w] for w in sent if w in model.wv.vocab]\n",
        "\n",
        "    sentvec[14:]=[]\n",
        "    sentvec.append(sentend)\n",
        "    if len(sentvec)<15:\n",
        "        for i in range(15-len(sentvec)):\n",
        "            sentvec.append(sentend) \n",
        "    sentvec=np.array([sentvec])\n",
        "    \n",
        "    predictions = model1.predict(sentvec)\n",
        "    outputlist=[model.most_similar([predictions[0][i]])[0][0] for i in range(15)]\n",
        "    output=' '.join(outputlist)\n",
        "    print(output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "all scrunchy concerts scrunchy scrunchy scrunchy scrunchy scrunchy scrunchy scrunchy scrunchy scrunchy scrunchy scrunchy scrunchy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "IsorYoDMHUgY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y6oKto2xHWrI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Using Glove (Used in best model)"
      ]
    },
    {
      "metadata": {
        "id": "c3qk-Djkuu8y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from gensim.scripts.glove2word2vec import glove2word2vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UtHd-RY8uygX",
        "colab_type": "code",
        "outputId": "2d4fee87-2e14-48df-f980-3009bd4eaaa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "glove_input_file = '/content/drive/My Drive/glove.6B.100d.txt'\n",
        "word2vec_output_file = '/content/drive/My Drive/glove.6B.100d.txt.word2vec'\n",
        "glove2word2vec(glove_input_file, word2vec_output_file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400000, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "IS51wkmkwd3E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "# load the Stanford GloVe model\n",
        "filename = '/content/drive/My Drive/glove.6B.100d.txt.word2vec'\n",
        "modelW2 = KeyedVectors.load_word2vec_format(filename, binary=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d2ybGFokJw69",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vec_xW2=[]\n",
        "vec_yW2=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9pzRSiN3va-L",
        "colab_type": "code",
        "outputId": "c89ffd49-0dce-4b64-d96c-df3d5a4462f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "for sent in tok_x:\n",
        "    sentvecW2=[modelW2[w] for w in sent if w in modelW2.wv.vocab]\n",
        "    vec_xW2.append(sentvecW2)\n",
        "for sent in tok_y:\n",
        "    sentvecW2=[modelW2[w] for w in sent if w in modelW2.wv.vocab]\n",
        "    vec_yW2.append(sentvecW2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "xvVkrUVhxBLt",
        "colab_type": "code",
        "outputId": "cccfdd07-10d2-4821-cfda-b453f219a5b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "print(modelW2['intestine'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.62042   -0.44278   -0.2186    -0.30858   -0.13381    0.81947\n",
            " -0.33076    0.57991    1.3364    -0.073734  -0.19904    0.50422\n",
            " -0.073423  -0.017576   0.3943     0.15761   -1.0546     0.19131\n",
            "  0.86593   -0.84506   -0.36739    0.080655  -0.77168    0.38065\n",
            "  0.72234    0.60594   -0.3287    -0.11697    0.4411     0.43\n",
            "  0.56769    0.0022013  0.61463   -0.1917     0.044901   0.63421\n",
            "  0.93268    0.24632   -0.49653    0.56145    0.54537   -0.15868\n",
            " -0.55126   -0.66917    0.27606    0.27682   -0.053004   0.053204\n",
            " -0.3405     1.2517     0.52948    0.31161    0.19862   -0.30229\n",
            " -0.98811    0.015316  -0.69401   -0.6074    -0.15286    0.33907\n",
            " -0.30487    0.74635    1.3338     0.73427    0.78453   -0.037469\n",
            " -0.53143   -0.80343    0.388     -1.121      0.21157   -0.0096739\n",
            "  0.46897    0.35062    0.16508   -0.41812   -1.1375     0.1181\n",
            " -0.08616    0.44691   -0.25886    1.2161    -0.83375    0.64782\n",
            " -0.60257   -0.13727    0.67729    0.094459  -0.93826    0.27251\n",
            "  0.091865  -0.80519    0.24083    0.34851   -0.33809    0.035758\n",
            "  0.81553   -0.78395    0.49255   -0.42039  ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ENAfKksnLbmh",
        "colab_type": "code",
        "outputId": "496ca855-71ca-4f7e-ea39-4dfd6bde14eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "vec_xW2[0][0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "metadata": {
        "id": "C-5TmZ1IL7h0",
        "colab_type": "code",
        "outputId": "18735d37-6275-4976-b24d-e7cfd62ba314",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "size = 0\n",
        "for i in vec_xW2:\n",
        "  size = max(size, len(i))\n",
        "print(size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2470\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sfbQ4xuaMGax",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for tok_sent in vec_xW2:\n",
        "  tok_sent[:-14]=[]\n",
        "  tok_sent.append(sentend)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mu-fFa_kMMdT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for tok_sent in vec_xW2:\n",
        "  if(len(tok_sent)<15):\n",
        "    for i in range(15-len(tok_sent)):\n",
        "      tok_sent.append(sentend)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eBmcqOQAMOma",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for tok_sent in vec_yW2:\n",
        "  tok_sent[14:]=[]\n",
        "  tok_sent.append(sentend)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JL1Inw-wMQFL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for tok_sent in vec_yW2:\n",
        "  if(len(tok_sent)<15):\n",
        "    for i in range(15-len(tok_sent)):\n",
        "      tok_sent.append(sentend)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-8bAFgbmMj7y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vec_XW2=np.array(vec_xW2,dtype=np.float64)\n",
        "vec_YW2=np.array(vec_yW2,dtype=np.float64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mE9md6cpxKnu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# vec_xW2=tf.keras.preprocessing.sequence.pad_sequences(vec_xW2,dtype='float64',padding='post',maxlen=15)\n",
        "vec_XW2=np.array(vec_xW2,dtype=np.float64)\n",
        "# X_train = sequence.pad_sequences(X_train, dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b62X0UYT7MQV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# vec_yW2=tf.keras.preprocessing.sequence.pad_sequences(vec_yW2,dtype='float64',padding='post',maxlen=15)\n",
        "vec_YW2=np.array(vec_yW2,dtype=np.float64)\n",
        "# X_train = sequence.pad_sequences(X_train, dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LsdGNsU-xZsQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_trainW2,x_testW2,y_trainW2,y_testW2 = train_test_split(vec_XW2,vec_YW2,test_size=0.2,random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6aZ3WHvmOMnk",
        "colab_type": "code",
        "outputId": "785ee9b2-0fb6-4fe4-f41e-ea135dabe92f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "x_trainW2.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7221, 15, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "metadata": {
        "id": "WP74VlDYx7eI",
        "colab_type": "code",
        "outputId": "423ef9b4-c7a7-4c84-e69c-71b3f113c15a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "cell_type": "code",
      "source": [
        "model1.fit(x_trainW2,y_trainW2,nb_epoch=5,validation_data=(x_testW2,y_testW2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 7221 samples, validate on 1806 samples\n",
            "Epoch 1/5\n",
            "7221/7221 [==============================] - 40s 5ms/step - loss: -0.6375 - acc: 0.3440 - val_loss: -0.6581 - val_acc: 0.3546\n",
            "Epoch 2/5\n",
            "7221/7221 [==============================] - 30s 4ms/step - loss: -0.6569 - acc: 0.3594 - val_loss: -0.6568 - val_acc: 0.3546\n",
            "Epoch 3/5\n",
            "7221/7221 [==============================] - 30s 4ms/step - loss: -0.6583 - acc: 0.3594 - val_loss: -0.6597 - val_acc: 0.3546\n",
            "Epoch 4/5\n",
            "7221/7221 [==============================] - 30s 4ms/step - loss: -0.6595 - acc: 0.3594 - val_loss: -0.6615 - val_acc: 0.3546\n",
            "Epoch 5/5\n",
            "7221/7221 [==============================] - 29s 4ms/step - loss: -0.6598 - acc: 0.3594 - val_loss: -0.6617 - val_acc: 0.3546\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fca9ceaf940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "metadata": {
        "id": "NviuFxkcyBe3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# vec_x=np.array(vec_x,dtype=np.float64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "01NAn2gWJJBq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictionsW2=model1.predict(x_testW2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XVCBIQZ9QZim",
        "colab_type": "code",
        "outputId": "9aa7ffe4-fdb9-49fa-899e-bb032aa28eee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "cell_type": "code",
      "source": [
        "[modelW2.most_similar([predictionsW2[5][i]])[0] for i in range(15)]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('i', 0.9310392737388611),\n",
              " ('so', 0.9105113744735718),\n",
              " ('so', 0.8989253044128418),\n",
              " ('just', 0.8730629682540894),\n",
              " ('just', 0.8340003490447998),\n",
              " ('just', 0.7725508809089661),\n",
              " ('just', 0.7000322937965393),\n",
              " ('one', 0.6328343152999878),\n",
              " ('inside', 0.6009101867675781),\n",
              " ('inside', 0.5746651887893677),\n",
              " ('inside', 0.5522726774215698),\n",
              " ('inside', 0.5309525728225708),\n",
              " ('inside', 0.4965549111366272),\n",
              " ('lying', 0.44810929894447327),\n",
              " ('dodecahedral', 0.3835752010345459)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "metadata": {
        "id": "dz7AdAIsQglc",
        "colab_type": "code",
        "outputId": "1b3884cc-b060-495c-fdf5-8bfb89f648b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "x=\"Hi how are you doing what is your name?\";\n",
        "sentend=np.ones((100,),dtype=np.float32) \n",
        "\n",
        "sent=nltk.word_tokenize(x.lower())\n",
        "sentvec = [modelW2[w] for w in sent if w in modelW2.wv.vocab]\n",
        "\n",
        "sentvec[:-14]=[]\n",
        "sentvec.append(sentend)\n",
        "if len(sentvec)<15:\n",
        "    for i in range(15-len(sentvec)):\n",
        "        sentvec.append(sentend) \n",
        "sentvec=np.array([sentvec])\n",
        "\n",
        "predictions = model1.predict(sentvec)\n",
        "outputlist=[modelW2.most_similar([predictions[0][i]])[0][0] for i in range(15)]\n",
        "output=' '.join(outputlist)\n",
        "print(output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "i so so just just just just one inside inside inside inside inside lying orientable\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Bg0mOT4WRyG9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_avWTo6Tumze",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Attention Mechanism Implementation"
      ]
    },
    {
      "metadata": {
        "id": "E3UJbxqDfMNI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Source:  [Attention for keras](https://machinelearningmastery.com/encoder-decoder-attention-sequence-to-sequence-prediction-keras/)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "QXk-ZcmtTx-x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras import regularizers, constraints, initializers, activations\n",
        "from keras.layers.recurrent import Recurrent\n",
        "from keras.engine import InputSpec\n",
        "\n",
        "tfPrint = lambda d, T: tf.Print(input_=T, data=[T, tf.shape(T)], message=d)\n",
        "\n",
        "def _time_distributed_dense(x, w, b=None, dropout=None,\n",
        "                           input_dim=None, output_dim=None, timesteps=None):\n",
        "    '''Apply y.w + b for every temporal slice y of x.\n",
        "    '''\n",
        "    if not input_dim:\n",
        "        # won't work with TensorFlow\n",
        "        input_dim = K.shape(x)[2]\n",
        "    if not timesteps:\n",
        "        # won't work with TensorFlow\n",
        "        timesteps = K.shape(x)[1]\n",
        "    if not output_dim:\n",
        "        # won't work with TensorFlow\n",
        "        output_dim = K.shape(w)[1]\n",
        "\n",
        "    if dropout:\n",
        "        # apply the same dropout pattern at every timestep\n",
        "        ones = K.ones_like(K.reshape(x[:, 0, :], (-1, input_dim)))\n",
        "        dropout_matrix = K.dropout(ones, dropout)\n",
        "        expanded_dropout_matrix = K.repeat(dropout_matrix, timesteps)\n",
        "        x *= expanded_dropout_matrix\n",
        "\n",
        "    # collapse time dimension and batch dimension together\n",
        "    x = K.reshape(x, (-1, input_dim))\n",
        "\n",
        "    x = K.dot(x, w)\n",
        "    if b:\n",
        "        x = x + b\n",
        "    # reshape to 3D tensor\n",
        "    x = K.reshape(x, (-1, timesteps, output_dim))\n",
        "    return x\n",
        "\n",
        "class AttentionDecoder(Recurrent):\n",
        "\n",
        "    def __init__(self, units, output_dim,\n",
        "                 activation='tanh',\n",
        "                 return_probabilities=False,\n",
        "                 name='AttentionDecoder',\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 recurrent_initializer='orthogonal',\n",
        "                 bias_initializer='zeros',\n",
        "                 kernel_regularizer=None,\n",
        "                 bias_regularizer=None,\n",
        "                 activity_regularizer=None,\n",
        "                 kernel_constraint=None,\n",
        "                 bias_constraint=None,\n",
        "                 **kwargs):\n",
        "        \"\"\"\n",
        "        Implements an AttentionDecoder that takes in a sequence encoded by an\n",
        "        encoder and outputs the decoded states\n",
        "        :param units: dimension of the hidden state and the attention matrices\n",
        "        :param output_dim: the number of labels in the output space\n",
        "\n",
        "        references:\n",
        "            Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio.\n",
        "            \"Neural machine translation by jointly learning to align and translate.\"\n",
        "            arXiv preprint arXiv:1409.0473 (2014).\n",
        "        \"\"\"\n",
        "        self.units = units\n",
        "        self.output_dim = output_dim\n",
        "        self.return_probabilities = return_probabilities\n",
        "        self.activation = activations.get(activation)\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "        self.recurrent_initializer = initializers.get(recurrent_initializer)\n",
        "        self.bias_initializer = initializers.get(bias_initializer)\n",
        "\n",
        "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
        "        self.recurrent_regularizer = regularizers.get(kernel_regularizer)\n",
        "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
        "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
        "\n",
        "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
        "        self.recurrent_constraint = constraints.get(kernel_constraint)\n",
        "        self.bias_constraint = constraints.get(bias_constraint)\n",
        "\n",
        "        super(AttentionDecoder, self).__init__(**kwargs)\n",
        "        self.name = name\n",
        "        self.return_sequences = True  # must return sequences\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        \"\"\"\n",
        "          See Appendix 2 of Bahdanau 2014, arXiv:1409.0473\n",
        "          for model details that correspond to the matrices here.\n",
        "        \"\"\"\n",
        "\n",
        "        self.batch_size, self.timesteps, self.input_dim = input_shape\n",
        "\n",
        "        if self.stateful:\n",
        "            super(AttentionDecoder, self).reset_states()\n",
        "\n",
        "        self.states = [None, None]  # y, s\n",
        "\n",
        "        \"\"\"\n",
        "            Matrices for creating the context vector\n",
        "        \"\"\"\n",
        "\n",
        "        self.V_a = self.add_weight(shape=(self.units,),\n",
        "                                   name='V_a',\n",
        "                                   initializer=self.kernel_initializer,\n",
        "                                   regularizer=self.kernel_regularizer,\n",
        "                                   constraint=self.kernel_constraint)\n",
        "        self.W_a = self.add_weight(shape=(self.units, self.units),\n",
        "                                   name='W_a',\n",
        "                                   initializer=self.kernel_initializer,\n",
        "                                   regularizer=self.kernel_regularizer,\n",
        "                                   constraint=self.kernel_constraint)\n",
        "        self.U_a = self.add_weight(shape=(self.input_dim, self.units),\n",
        "                                   name='U_a',\n",
        "                                   initializer=self.kernel_initializer,\n",
        "                                   regularizer=self.kernel_regularizer,\n",
        "                                   constraint=self.kernel_constraint)\n",
        "        self.b_a = self.add_weight(shape=(self.units,),\n",
        "                                   name='b_a',\n",
        "                                   initializer=self.bias_initializer,\n",
        "                                   regularizer=self.bias_regularizer,\n",
        "                                   constraint=self.bias_constraint)\n",
        "        \"\"\"\n",
        "            Matrices for the r (reset) gate\n",
        "        \"\"\"\n",
        "        self.C_r = self.add_weight(shape=(self.input_dim, self.units),\n",
        "                                   name='C_r',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.U_r = self.add_weight(shape=(self.units, self.units),\n",
        "                                   name='U_r',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.W_r = self.add_weight(shape=(self.output_dim, self.units),\n",
        "                                   name='W_r',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.b_r = self.add_weight(shape=(self.units, ),\n",
        "                                   name='b_r',\n",
        "                                   initializer=self.bias_initializer,\n",
        "                                   regularizer=self.bias_regularizer,\n",
        "                                   constraint=self.bias_constraint)\n",
        "\n",
        "        \"\"\"\n",
        "            Matrices for the z (update) gate\n",
        "        \"\"\"\n",
        "        self.C_z = self.add_weight(shape=(self.input_dim, self.units),\n",
        "                                   name='C_z',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.U_z = self.add_weight(shape=(self.units, self.units),\n",
        "                                   name='U_z',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.W_z = self.add_weight(shape=(self.output_dim, self.units),\n",
        "                                   name='W_z',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.b_z = self.add_weight(shape=(self.units, ),\n",
        "                                   name='b_z',\n",
        "                                   initializer=self.bias_initializer,\n",
        "                                   regularizer=self.bias_regularizer,\n",
        "                                   constraint=self.bias_constraint)\n",
        "        \"\"\"\n",
        "            Matrices for the proposal\n",
        "        \"\"\"\n",
        "        self.C_p = self.add_weight(shape=(self.input_dim, self.units),\n",
        "                                   name='C_p',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.U_p = self.add_weight(shape=(self.units, self.units),\n",
        "                                   name='U_p',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.W_p = self.add_weight(shape=(self.output_dim, self.units),\n",
        "                                   name='W_p',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.b_p = self.add_weight(shape=(self.units, ),\n",
        "                                   name='b_p',\n",
        "                                   initializer=self.bias_initializer,\n",
        "                                   regularizer=self.bias_regularizer,\n",
        "                                   constraint=self.bias_constraint)\n",
        "        \"\"\"\n",
        "            Matrices for making the final prediction vector\n",
        "        \"\"\"\n",
        "        self.C_o = self.add_weight(shape=(self.input_dim, self.output_dim),\n",
        "                                   name='C_o',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.U_o = self.add_weight(shape=(self.units, self.output_dim),\n",
        "                                   name='U_o',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.W_o = self.add_weight(shape=(self.output_dim, self.output_dim),\n",
        "                                   name='W_o',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.b_o = self.add_weight(shape=(self.output_dim, ),\n",
        "                                   name='b_o',\n",
        "                                   initializer=self.bias_initializer,\n",
        "                                   regularizer=self.bias_regularizer,\n",
        "                                   constraint=self.bias_constraint)\n",
        "\n",
        "        # For creating the initial state:\n",
        "        self.W_s = self.add_weight(shape=(self.input_dim, self.units),\n",
        "                                   name='W_s',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "\n",
        "        self.input_spec = [\n",
        "            InputSpec(shape=(self.batch_size, self.timesteps, self.input_dim))]\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, x):\n",
        "        # store the whole sequence so we can \"attend\" to it at each timestep\n",
        "        self.x_seq = x\n",
        "\n",
        "        # apply the a dense layer over the time dimension of the sequence\n",
        "        # do it here because it doesn't depend on any previous steps\n",
        "        # thefore we can save computation time:\n",
        "        self._uxpb = _time_distributed_dense(self.x_seq, self.U_a, b=self.b_a,\n",
        "                                             input_dim=self.input_dim,\n",
        "                                             timesteps=self.timesteps,\n",
        "                                             output_dim=self.units)\n",
        "\n",
        "        return super(AttentionDecoder, self).call(x)\n",
        "\n",
        "    def get_initial_state(self, inputs):\n",
        "        # apply the matrix on the first time step to get the initial s0.\n",
        "        s0 = activations.tanh(K.dot(inputs[:, 0], self.W_s))\n",
        "\n",
        "        # from keras.layers.recurrent to initialize a vector of (batchsize,\n",
        "        # output_dim)\n",
        "        y0 = K.zeros_like(inputs)  # (samples, timesteps, input_dims)\n",
        "        y0 = K.sum(y0, axis=(1, 2))  # (samples, )\n",
        "        y0 = K.expand_dims(y0)  # (samples, 1)\n",
        "        y0 = K.tile(y0, [1, self.output_dim])\n",
        "\n",
        "        return [y0, s0]\n",
        "\n",
        "    def step(self, x, states):\n",
        "\n",
        "        ytm, stm = states\n",
        "\n",
        "        # repeat the hidden state to the length of the sequence\n",
        "        _stm = K.repeat(stm, self.timesteps)\n",
        "\n",
        "        # now multiplty the weight matrix with the repeated hidden state\n",
        "        _Wxstm = K.dot(_stm, self.W_a)\n",
        "\n",
        "        # calculate the attention probabilities\n",
        "        # this relates how much other timesteps contributed to this one.\n",
        "        et = K.dot(activations.tanh(_Wxstm + self._uxpb),\n",
        "                   K.expand_dims(self.V_a))\n",
        "        at = K.exp(et)\n",
        "        at_sum = K.sum(at, axis=1)\n",
        "        at_sum_repeated = K.repeat(at_sum, self.timesteps)\n",
        "        at /= at_sum_repeated  # vector of size (batchsize, timesteps, 1)\n",
        "\n",
        "        # calculate the context vector\n",
        "        context = K.squeeze(K.batch_dot(at, self.x_seq, axes=1), axis=1)\n",
        "        # ~~~> calculate new hidden state\n",
        "        # first calculate the \"r\" gate:\n",
        "\n",
        "        rt = activations.sigmoid(\n",
        "            K.dot(ytm, self.W_r)\n",
        "            + K.dot(stm, self.U_r)\n",
        "            + K.dot(context, self.C_r)\n",
        "            + self.b_r)\n",
        "\n",
        "        # now calculate the \"z\" gate\n",
        "        zt = activations.sigmoid(\n",
        "            K.dot(ytm, self.W_z)\n",
        "            + K.dot(stm, self.U_z)\n",
        "            + K.dot(context, self.C_z)\n",
        "            + self.b_z)\n",
        "\n",
        "        # calculate the proposal hidden state:\n",
        "        s_tp = activations.tanh(\n",
        "            K.dot(ytm, self.W_p)\n",
        "            + K.dot((rt * stm), self.U_p)\n",
        "            + K.dot(context, self.C_p)\n",
        "            + self.b_p)\n",
        "\n",
        "        # new hidden state:\n",
        "        st = (1-zt)*stm + zt * s_tp\n",
        "\n",
        "        yt = activations.softmax(\n",
        "            K.dot(ytm, self.W_o)\n",
        "            + K.dot(stm, self.U_o)\n",
        "            + K.dot(context, self.C_o)\n",
        "            + self.b_o)\n",
        "\n",
        "        if self.return_probabilities:\n",
        "            return at, [yt, st]\n",
        "        else:\n",
        "            return yt, [yt, st]\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\"\n",
        "            For Keras internal compatability checking\n",
        "        \"\"\"\n",
        "        if self.return_probabilities:\n",
        "            return (None, self.timesteps, self.timesteps)\n",
        "        else:\n",
        "            return (None, self.timesteps, self.output_dim)\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"\n",
        "            For rebuilding models on load time.\n",
        "        \"\"\"\n",
        "        config = {\n",
        "            'output_dim': self.output_dim,\n",
        "            'units': self.units,\n",
        "            'return_probabilities': self.return_probabilities\n",
        "        }\n",
        "        base_config = super(AttentionDecoder, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hGtRwdTuUCOv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "11KEEQePkiPE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install chatterbot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ftizcK6okjZr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from chatterbot import ChatBot\n",
        "from chatterbot.trainers import ListTrainer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bqra8XNdkuMz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "chatterbot = ChatBot('Ron Obvious',read_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KGE-A48wk2MI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# trainer = ChatterBotCorpusTrainer(chatbot)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iSAlfopqk5Wt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# trainer.train(friends_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y3QOLCkHk-0L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "chatterbot.set_trainer(ListTrainer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kGrUm6IEl45a",
        "colab_type": "code",
        "outputId": "54afca08-98ec-4e06-829d-4b47cef746d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "chatterbot.train(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "List Trainer: [####################] 100%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HhZpHCsGmaAL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(chatterbot.get_response(\"Hi\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IUvVrWWrKgAw",
        "colab_type": "code",
        "outputId": "13fa0b24-21e6-42eb-d23c-982d28c34fb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(chatterbot.get_response(\"Hi\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This guy says hello I wanna kill myself\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Wu9kAGTbK1lq",
        "colab_type": "code",
        "outputId": "b02da284-153f-4eb7-81c9-b84a3747f32f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(chatterbot.get_response(\"kya kr rhi thi?\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kya kr rhi thi?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S41ABduufHpA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    }
  ]
}